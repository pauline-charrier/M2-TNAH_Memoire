\subsection{Le corpus Doucet : caractéristiques graphiques et objectifs de normalisation}

Avant de nous pencher sur les anomalies récurrentes observables dans le corpus de correspondances (1908-1929) entre Jacques Doucet et René-Jean, ayant fait l’objet d’une transcription imitative\footnote{Voir les chapitres 2 et 4 du présent mémoire.} rappelons brièvement son contexte de production. Il s’agit d’une partie d’un échange épistolaire privé (les lettres expédiées par Doucet et reçues par René-Jean), non destiné à la publication, s’étendant sur une période relativement étendue, et concentré en une assez modeste volumétrie (moins de 100 lettres pour le corpus actuellement traité (2024) par le projet \pense). Ne présentant, pour la majeure partie des documents, qu’un scripteur unique (Doucet), à quelques exceptions très localisées (ajouts manuscrits de René-Jean, numérotation introduite par Sylvie Maignan…), l’écriture est manuscrite, cursive et susceptible de présenter des difficultés à la lecture.

En ce qui concerne la conformité avec les conventions orthographiques et syntaxiques (ponctuation…), un certain nombre d’anomalies récurrentes sont observables dans le corpus, ce qui interroge notamment en ce qui concerne le rapport de Doucet à l’écriture, et plus largement la nature des pratiques d’écriture à l’époque et dans le milieu social de Doucet. On peut se demander s'il s'agit de caractéristiques propres à cette époque ou au processus d'apprentissage de l’écriture tel qu’on l'enseignait aux enfants au moment de l'enfance de Doucet. Cependant, il est difficile de se prononcer de manière définitive, faute de documentation scientifique suffisante sur ce point. Il semble néanmoins pertinent de souligner certains éléments notables.

\subsubsection{Typologies d’anomalies fréquemment rencontrées}

\begin{center}     
\begin{longtable}{|p{5cm}|p{5cm}|p{5cm}|}
    \hline
    \textbf{Type d'anomalie} & \textbf{Exemple} & \textbf{Correction attendue}\endfirsthead \\ \hline
    \textbf{Type d'anomalie} & \textbf{Exemple} & \textbf{Correction attendue}\endhead \\ \hline
    
    Absence d’accentuation ou accentuation inexacte/irrégulière & « il vous expediera » (bnf\_naf13124\_2\_61),\newline « du plus grand interét presentée avec » (bnf\_naf13124\_2\_59) & « il vous expédiera […] »,\newline « du plus grand intérêt présenté avec […] » \\ \hline
    Absence de ponctuation (point et virgule) & « Nous sommes en bonne santé Amitié à tous » (bnf\_naf13124\_2\_61),\newline « vous l'enverra moyennant finance bien entendu c'est un homme precieux pour l'Art chretien. » (bnf\_naf13124\_2\_60) & « Nous sommes en bonne santé. Amitié à tous. »,\newline « vous l’enverra moyennant finances, bien entendu c’est un homme précieux pour l’Art chrétien. » \\ \hline
    Substitution de la virgule par le point & « et de vos bons souhaits. nous revoila » (bnf\_naf13124\_2\_60) & « et de vos bons souhaits, nous revoilà […] » \\ \hline    
    Absence de tirets dans les inversions sujet-verbe & « Avons nous une revue grecque sur l'art chretien » (bnf\_naf13124\_2\_60) & « Avons-nous un revue grecque sur l’art chrétien […] ? » \\ \hline   
    Substitution du point d’interrogation par un point final. & « toutes celles que ce
Simiriottis a pu me livrer sont marquees dans son catalogue joint a l'envoi, il doit completer ce qui manque mais quand. » (bnf\_naf13124\_2\_61) & « toutes celles que ce Simiriottis a pu me livrer sont marquées dans son catalogue joint à l’envoi, il doit compléter ce qui manque, mais quand ? » [hypothèse interprétative] \\ \hline    
    Substitution du point par le tiret & « Faites moi donc creance d'une semaine ou deux - Merci et bien à vous. » (bnf\_naf13124\_2\_52),\newline « j'ai été si pris par les mille choses qu'il faut que je fasse moi-même qu'il ne m'a pas été possible de venir un peu causer avec vous - Je vais bien moral et physique voici pour moi. » (bnf\_naf13124\_2\_49) & « Faites-moi donc créance d’une semaine ou deux. Merci et bien à vous. »,\newline « J’ai été si pris par les mille choses qu’il faut que je fasse moi-même qu’il ne m’a pas été possible de venir un peu causer avec vous. Je vais bien, moral et physique, voici pour moi. » \\ \hline 
    \caption{Typologie des anomalies fréquemment rencontrées dans le corpus Doucet.} % Légende sous le tableau
\end{longtable}   
\end{center}

Premièrement, ces anomalies semblent rappeler un usage de la ponctuation qui pourrait être qualifié d'« oral » ou « à l’ancienne », rappelant des pratiques de l’écriture du XVIIIe siècle, où l’usage de la ponctuation visait à refléter les pauses respiratoires dans le discours oral. Comme le remarque Annette Lorenceau, cette approche de la ponctuation, substituant la virgule par un point et le point final par un tiret par exemple, s'éloigne des règles strictement grammaticales privilégiées au XIXe siècle, se caractérisant par une utilisation plus codifiée et plus abondante (voire excessive, du point de vue contemporain) des signes de ponctuation\footcite[p.51]{lorenceau_ponctuation_1980}. Ce phénomène, observé chez Doucet, pourrait s'expliquer par plusieurs hypothèses aux appuis néanmoins relativement faibles, que nous émettons ci-après. D’une part, la familiarité de Doucet, que l’on sait grand collectionneur d’art du XVIIIème, avec la culture livresque de cette époque, pourrait avoir influencé son écriture. D'autre part, une certaine habitude de la dimension orale des échanges (écrivant à ses destinataires comme il parle à ses collaborateurs) pourrait justifier une écriture proche du langage parlé. Il est également à noter que l’usage du tiret comme d’un point final est notée par Marie-Anne Sarda, chercheuse responsable de l’édition numérique de la correspondance de Doucet, comme « courante » au XIXème siècle\footcite{carius_principes_2024}. Remarquons que dans ce cas précis, il est également possible qu’il s’agisse d’un simple choix de représentation graphique consistant à étendre le tracé du point final jusqu’à le faire ressembler à un tiret.

\subsubsection{Résultat souhaité par la recherche}
Le projet \pense s’inscrit dans une volonté de maintenir une continuité avec les traditions de l’édition papier tout en proposant une expérience de lecture adaptée aux possibilités offertes par le numérique. En s'inspirant des corpus alignés bilingues, comme le montre l'exemple du projet \textit{Architrave}\footcite{noauthor_architrave_nodate}, ainsi que des éditions génétiques, telles que \textit{E-Balzac}, \pense cherche avec l’édition Doucet, nous l’avons déjà dit, à offrir une double lecture : d’une part, une édition diplomatique imitative, respectant la matérialité du manuscrit, et d’autre part, une édition critique plus classique, conforme aux normes modernes d’édition de textes manuscrits\footcite{carius_principes_2024}.
Cette double approche permettrait aux lecteurs de naviguer facilement entre ces deux versions, éventuellement à terme grâce à un système d’onglets interactifs (comme dans l’édition \textit{Architrave}), offrant ainsi une expérience enrichie. 
Il s’agit donc pour l’étape de la correction devant servir de base à l’édition critique, de proposer une lecture facilitée au lecteur : les anomalies les plus fréquemment retrouvées, à savoir les erreurs de ponctuation et d’accentuation, doivent donc faire l’objet d’une normalisation, selon la forme proposée ci-dessus. Pour cela, et en s’inscrivant dans la dimension expérimentale affirmée de \pense, nous avons fait le choix de nous pencher sur les perspectives proposées par l’\ia générative. 

\subsubsection{Présentation des outils choisis}
Nous nous sommes tournés vers l’\api de GPT 3.5, qui s'est avéré être un choix pertinent en raison de sa facilité de prise en main et de sa capacité à traiter des tâches complexes sans nécessiter un entraînement spécifique du modèle. Cette décision a été motivée par des contraintes de temps et d'infrastructure, en lien avec le cadre temporel du projet. Bien que l’utilisation de cette \api soit payante, le coût par token\footnote{Un token, dans le contexte de l’\api GPT, représente une unité minimale de texte, composée de quelques caractères ou mots, utilisée par le modèle pour générer une réponse. Chaque requête envoyée à l’\api se voit facturer en fonction du nombre de tokens consommés (tokens fournit en entrée par l’utilisateur et tokens produits en sortie par l’IA générative) ce qui permet de mesurer la quantité de texte traité lors de chaque opération.} s’est révélé compatible avec les besoins du projet, le corpus à traiter étant d’une volumétrie assez faible. La préférence pour l’\api plutôt que pour l’interface de Chat de GPT se justifie par un meilleur contrôle des paramètres du prompt, les capacités de systématisation (application du prompt à un corpus de plusieurs fichiers) et par la possibilité de produire des fichiers au format TXT directement en sortie. 
En parallèle, Google Colab a été utilisé comme environnement de travail pour faciliter les expérimentations initialement envisagées, avec des modèles plus spécifiques, comme le \mlm CamemBERT, du fait de sa capacité à exploiter des ressources GPU externes (ressources limitées fournies par Google). Ce choix s’explique par le besoin de ressources informatiques supplémentaires, notamment pour des tâches de fine-tuning de modèles. Google Colab, bien que soumis à certaines limitations en termes de temps d’exécution et de ressources, nous permettait alors de surmonter un certains nombres de contraintes. Bien que le recours à un \mlm ait été finalement abandonné du fait de difficultés techniques, nous avons conservé l’usage aux notebooks de Google Colab par confort et ergonomie.

\textbfit{L’enjeu de la réplicabilité}\newline
Un enjeu majeur de l’usage de grand modèle de langage pour des tâches spécifiques concerne la réplicabilité : le modèle étant entraîné avec des données d’apprentissage massives combinées à des milliards de paramètres pouvant apparaître comme peu aisément manipulables, voire comme une véritable « boîte noire » pour l’utilisateur, comment s’assurer que le modèle générera la même réponse au même prompt quelle que soit les conditions ? Pour essayer de limiter les variations, il s’agit de configurer un certains nombres de paramètres dont notamment la température. 
Dans le contexte du \textit{prompt engineering} (que l’on peut définir comme l’ensemble des méthodes, exprimées en langage naturel ou sous forme de code de plus bas niveau, permettant de modeler la réponse fournie par un modèle d’IA générative), la température est un paramètre clé permettant de moduler la créativité d’un modèle de langage. En abaissant la température, on favorise des réponses plus déterministes, où le modèle aura moins tendance à explorer des alternatives variées et créatives (mais aussi plus susceptibles de virer à l’hallucination). En revanche, une température élevée encourage des réponses plus créatives, mais moins prévisibles. Le contrôle de ce paramètre apparaît donc essentiel pour obtenir des résultats reproductibles dans le cadre de l'utilisation des \llm\footcite{reddy_controlling_2024}.
D'autres paramètres, comme le \textit{top-k} et le \textit{top-p}, peuvent également être ajustés pour moduler la sortie générée par le modèle. Le paramètre \textit{top-k} restreint les choix possibles du modèle aux \textbf{k}\footnote{Le « k » dans top-k se réfère seulement à un sous-ensemble des meilleurs éléments.} mots les plus probables à chaque étape de génération, tandis que \textit{top-p} (ou \textit{nucleus sampling}, échantillonnage de noyau) permet de considérer uniquement les mots dont la probabilité cumulée atteint un certain seuil\footcite{weinmeister_beyond_2024}. De même que pour la température, plus les valeurs assignées à ces paramètres sont basses, plus les réponses susceptibles d’être générées seront jugées statistiquement probables. Ces ajustements offrent un contrôle plus fin sur la qualité et la cohérence des résultats produits par le \llm. En les combinant avec la température, il est possible d’influencer la variabilité des réponses tout en maintenant une certaine cohérence dans les sorties.

\subsection{Requêtage de l’API de GPT 3.5 pour la correction automatique de texte non balisé}
\subsubsection{Présentation technique de l’outil}

L’\api GPT 3.5, développée par OpenAI, repose sur un modèle de langage de grande taille (\llm, \textit{Large Language Model}), capable de générer du texte en se basant sur des milliards de paramètres et d'un corpus textuel immense, comprenant notamment une partie du web archivé par l’organisation Common Crawl pour GPT 3\footcite[p.8]{brown_language_2020}. Ces modèles utilisent des techniques d’apprentissage profond pour analyser des séquences textuelles et générer des prédictions, permettant ainsi de produire des réponses pertinentes aux requêtes sous la forme de texte structuré. La version GPT 3.5, sortie en 2022, version affinée du modèle précédent GPT-3, constitue l’outil sur lequel nous allons nous concentrer ici. 

\textbfit{Qu’est-ce qu’une API ?}\newline
Une \api, ou interface de programmation applicative, selon la définition donnée par Frédéric Clavert, est « un dispositif logiciel qui permet à deux programmes d’échanger, par exemple, des fonctionnalités ou des données » \footcite{clavert_gout_2017}. Dans le cas de GPT 3.5, l’\api offre un accès direct aux capacités du modèle pour des tâches variées telles que la génération de texte ou la correction automatique, sans avoir à passer par l’interface de Chat, qui, bien qu’ergonomique, comporte un certain nombre de limites, notamment en ce qui concerne le contrôle des paramètres orientant le prompt. 

\subsubsection{Le prompt engineering}
\textbfit{Principes et méthodes}\newline

L’un des aspects essentiels de l’utilisation des \llm pour la génération de texte est l'optimisation du \textit{prompt engineering}. Cette approche consiste à formuler des requêtes (\textit{prompts}) de manière à maximiser la pertinence et la qualité des réponses fournies par le modèle. Le \textit{prompt engineering} repose sur la maîtrise des différents paramètres disponibles, tels que la température, pour ajuster la sortie générée. En fonction des objectifs recherchés, il est possible d’affiner les réponses, d'améliorer leur précision ou d’encourager la créativité du modèle. Selon les approches adoptées, le processus peut inclure plusieurs variantes, comme le \textit{zero-shot}\footnote{Une instruction est donnée au modèle, sans exemple spécifique au préalable de ce qui est attendu.}  , le \textit{one-shot}\footnote{Un seul exemple est fourni au modèle en plus de l’instruction, pour affiner sa réponse.} ou le \textit{few-shot prompting}\footnote{Plusieurs exemples sont fournis au modèle.}, chacune présentant un degré variable de contextualisation nécessaire pour orienter la réponse\footcite{aryani_8_2023}. Diverses méthodes utilisant le langage naturel, dont l’efficacité n’est pas toujours bien mise en évidence dans la littérature scientifique, ont été proposées pour augmenter les chances d’obtenir un résultat adéquat, comme le fait d’assigner explicitement un rôle au modèle  (« Tu es un correcteur automatique ») ou de lui demander de développer son raisonnement dans sa réponse(méthode de la \textit{chain of thought}) \footcite{noauthor_prompt_nodate}. 

\textbfit{Enjeux linguistiques}\newline
Les prompts en langage naturel peuvent être rédigés dans toutes les langues pour lesquelles le modèle dispose de données d’entraînement. Nous pouvons penser que plus les données d’entraînement sont massives dans une langue donnée, plus le modèle est performant pour accomplir la tâche demandée. C’est la raison pour laquelle une réflexion a d’abord été menée pour déterminer si le prompt devait être rédigé en français ou en anglais, langue très largement représentée sur le Web, et qui, on l’imagine, constitue la majeure partie des données d’entraînement. Cependant, selon une étude menée avec GPT 3.5 en 2024, il n’existe pas de différence massive de performance entre les langues les plus largement représentées en ce qui concerne l’efficacité des prompts\footcite{jordan_need_2024}. Seules les langues très peu dotées (comme le tamoul, dans l’étude citée), pâtissant de leur faible représentation au sein du corpus d’entraînement. Le français étant très bien dotée sur le Web (étant la 4ème langue la plus utilisée), il n’est donc pas si évident qu’un prompt en anglais donne de meilleurs résultats qu’un prompt en français, d’autant que le texte à analyser puis à générer, lui, se trouve en français. Nous avons donc fait le choix de rédiger notre prompt en français. Il aurait été intéressant d’approfondir cette étude par une approche comparative qui aurait permis d’aligner les résultats obtenus avec un prompt français et avec un prompt anglais, mais du fait, notamment, de contraintes de temps, cette exploration n’a pu être pleinement menée.
Le prompt finalement choisi est finalement d’une grande simplicité et a surtout exploité les possibilités offertes avec le prompt en langage naturel, se concentrant sur des instructions claires et brèves et fournissant au moins un exemple de résultat attendu.

\subsubsection{Evaluation de la qualité du résultat obtenu}
Pour évaluer la qualité des corrections proposées dans le cadre de notre projet, nous avons mobilisé plusieurs métriques issues du domaine du traitement automatique du langage naturel (TAL ou NLP pour \textit{natural language processing}). Chacune de ces métriques présente des avantages spécifiques en fonction du type de tâches à évaluer, et permet d’obtenir une vue d’ensemble des performances du modèle employé. Toutefois, il est essentiel de contextualiser ces mesures et d’en comprendre les limites dans le cadre précis de la correction automatique, une tâche qui souvent diffère, parfois grandement, des objectifs initiaux pour lesquels ces outils ont été conçus.

\textbfit{Le score ROUGE}\newline
Le \textit{ROUGE Score} (pour \textit{Recall-Oriented Understudy for Gisting Evaluation}) \footnote{Pour le papier de référence introduisant cette métrique, voir \footcite{lin_rouge_2004}} est une métrique fréquemment utilisée pour évaluer la qualité de résumés générés automatiquement, comparant la similarité entre un résumé généré par machine et un ou plusieurs résumés « de référence » rédigés par l’humain (assimilables à des vérités terrains (ou \textit{groundtruth})), et en mesurant les recouvrements de n-grams (unités de mots consécutifs) ainsi que de séquences de mots plus longues. Le score est généralement décliné en plusieurs variantes, notamment ROUGE-1, ROUGE-2 et ROUGE-L, qui mesurent respectivement le recouvrement de unigrammes, de bigrammes et de la plus longue sous-séquence commune (LCS) entre les résumés générés et les résumés de référence\footcite{santhosh_understanding_2023}.
Dans le cadre de notre étude, à partir de la comparaison entre les corrections générées par GPT 3.5 et les corrections manuelles, nous avons obtenu les scores suivants : ROUGE-1 : 0.9756, ROUGE-2 : 0.9537 et ROUGE-L : 0.9756. Ces résultats indiquent une forte similarité (une similarité parfaite correspondant à un résultat de « 1 ») entre les corrections proposées par notre modèle et les corrections effectuées par un humain, en particulier en ce qui concerne les unigrammes et les séquences de mots plus longues. 

Cependant, cette proximité élevée ne signifie pas nécessairement que la correction est parfaite ou exempte d’erreurs. En effet, bien que le modèle reproduise efficacement des chaînes de mots similaires aux références, il n’est pas garanti que ces chaînes soient les plus pertinentes ou les plus correctes dans le contexte de la correction automatique. Ces scores doivent donc être interprétés avec précaution. 

\textbfit{Le score BLEU}\newline
Le \textit{BLEU Score} (pour \textit{Bilingual Evaluation Understudy}) \footnote{Pour le papier de référence introduisant cette métrique, voir : \footcite{papineni_bleu_2002}} est une autre mesure habituellement utilisée notamment pour évaluer la qualité des traductions générées par des machines. 

Similairement au score ROUGE, BLEU évalue la proximité entre une traduction produite par un modèle et une ou plusieurs traductions de référence rédigées par un humain en calculant la proportion de n-grams partagés entre ces traductions\footcite{santhosh_understanding_2023}. Contrairement à ROUGE, qui favorise le rappel\footnote{Le rappel étant le rapport entre le nombre de vrais positifs (les éléments ayant été correctement identifiés par le modèle comme pertinents) et le nombre total d'éléments pertinents (qui inclut à la fois les vrais positifs et les faux négatifs, c'est-à-dire les éléments pertinents qui n'ont pas été identifiés comme tels).}  , BLEU met davantage l'accent sur la précision, c'est-à-dire sur la proportion de segments générés qui correspondent effectivement aux segments de référence.

Dans le cadre de l’étude portant sur la correction du corpus Doucet, nous avons calculé un \textit{BLEU score} de 0.7607. Ce score, relativement élevé, indique que le modèle parvient à générer des corrections qui, en grande partie, correspondent aux corrections attendues. Toutefois, il est important de souligner que BLEU, à l’instar de ROUGE, ne prend pas en compte le contexte grammatical ou sémantique global dans lequel les corrections sont effectuées. Par conséquent, bien que ce score témoigne d’une certaine qualité des corrections, il ne garantit pas que celles-ci soient toujours absolument appropriée.

\textbfit{La distance de Levenshtein}\newline
La distance de Levenshtein est une mesure de la différence entre deux chaînes de caractères données, exprimée par le nombre minimal d’opérations nécessaires (insertion, suppression, substitution de caractères) pour transformer une chaîne en une autre.
Dans notre projet, la distance de Levenshtein moyenne calculée est de 142.25. Ce résultat, qui peut sembler élevé au premier abord doit cependant être interprété eu égard à la volumétrie du corpus. Un score de Levenshtein élevé signifie a priori que les corrections apportées par le modèle impliquent un grand nombre de modifications par rapport au texte corrigé manuellement, cependant, plus le corpus à traiter comporte de caractères, plus les opportunités de modification sont élevées. Des petites différences de correction dispersées sur l’ensemble du corpus sont ainsi susceptibles de s’accumuler et d’être perceptibles lors de l’obtention du résultat. Il ne faut cependant pas ignorer une possible tendance à la sur-correction de la part du modèle qui peut également expliquer cette distance relativement importante.

\textbfit{Des métriques adaptées à l’évaluation d’une tâche de correction automatique ?}\newline
Bien que ces métriques aient été conçues pour évaluer des tâches comme la traduction automatique ou la génération de résumés, elles peuvent néanmoins fournir des indications pertinentes dans le cadre de la correction automatique, en ce que leur utilisation permet de proposer une représentation quantitative du degré de similitude entre textes corrigés par la machine et textes corrigés par l’humain (correspondant à une « vérité terrain »). Cependant, il demeure important de noter que ces outils n’évaluent pas la pertinence sémantique ou grammaticale des corrections proposées. Par conséquent, ils ne suffisent pas à eux seuls pour garantir la qualité d'une correction automatique dans sa globalité – ce qu’a priori seule une vérification manuelle humaine est capable d’assurer encore aujourd’hui.

\subsubsection{Limites de l’expérience}
\textbfit{Paramétrage du prompt}\newline

Le prompt utilisé aurait gagné à être optimisé en ajustant certains paramètres spécifiques des modèles génératifs tels que la \textit{temperature} et le \textit{top-k}. Ces paramètres, qui contrôlent respectivement la diversité des réponses générées et la taille de l’échantillon des réponses possibles, n’ont pas été entièrement mobilisés dans le cadre de notre expérience (seule la température, fixée à 0,7 a été incluse, mais nous n’avons pas effectué de comparaisons approfondies avec d’autres niveaux de températures). Un meilleur ajustement de ces variables aurait peut-être permis de limiter les cas de sur-correction ou d’améliorer la qualité des propositions de correction.

\textbfit{Contraintes de temps et d’infrastructure}\newline

L’expérience s’est également déroulée dans un cadre contraint, avec une durée d’une semaine et un nombre limité de tokens disponibles pour le traitement des données. Ces contraintes ont limité la possibilité d’expérimenter avec des ajustements de paramètres ou des configurations alternatives du modèle, ce qui aurait pu permettre d'obtenir des résultats plus fins.

\subsection{Quelles alternatives au LLM pour la correction neuronale du corpus Doucet ?}

\subsubsection{La piste des modèles MLM et Seq2Seq à l’épreuve de la correction textuelle}

Dans la recherche d'alternatives aux \llm, les modèles Seq2Seq et \mlm\footnote{Voir chapitre 6.} constituent a priori des candidats intéressants pour la correction automatique, compte tenu de leurs performances sur des tâches de TAL analogues (traduction notamment). Toutefois, leur mise en œuvre nécessite un entraînement spécifique en raison des défis particuliers posés par notre corpus. Il s’agit ici de la limite principale que nous pouvons identifier, et qui explique le fait que nous n’ayons pas pu mettre en œuvre ces alternatives au cours de notre stage.

\textbfit{Modèles de type MLM}\newline
Comme nous l’avons évoqué brièvement plus tôt dans ce mémoire, les modèles de type \mlm, tels que CamemBERT\footcite{martin_camembert_2020} et FlauBERT développés par l’INRIA pour le français, sont pré-entraînés sur des volumes massifs de données textuelles, pour prédire les mots manquants (ou « masqués ») dans une phrase donnée. Cependant, dans le cadre de notre corpus, des ajustements spécifiques sont nécessaires pour tenir compte des erreurs fréquentes, comme la présence d’espaces surnuméraires, les problèmes de capitalisation, de ponctuation, et d’accentuation.

\textbfit{Modèles Seq2Seq}\newline
Les modèles Seq2Seq, tels que \textit{MBART}, \textit{T5} ou encore \textit{BARThez} pour le français, offrent une autre alternative. Ces modèles reposent sur une architecture de transformation dite « séquence-à-séquence », qui les rend particulièrement adaptés pour des tâches nécessitant des révisions complexes d’un texte. Cependant, comme pour les \mlm, ces modèles doivent être entraînés sur notre corpus pour prendre en compte ses particularités. Un modèle potentiellement intéressant que nous avions identifié au cours de notre stage est un modèle de type « ByT5 » de correction textuelle disponible sur la plateforme \textit{Hugging Face}\footnote{Voir https://huggingface.co/sdadas/byt5-text-correction.}. Bien que pré-entraîné sur des tâches correspondant à nos besoins, ce modèle présente des limitations majeures vis-à-vis de l’usage que nous envisagions d’en faire. D’une part, il nécessite un pré-traitement des fichiers afin de les rendre compatibles avec les exigences du modèle, comprenant notamment l’ajout de préfixes de langue, d’autre part ce modèle est considérablement limité par la taille des fichiers qu’il peut traiter, étant surtout approprié pour des corrections locales de phrases isolées, ce qui imposerait de fragmenter nos données avant traitement, une tâche possiblement chronophage et pouvant être évitée avec d’autres solutions.